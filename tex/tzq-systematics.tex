\chapter{Background Estimation}\label{chapter:bkg}
%Monte Carlo simulated samples are used to model the signal and background processes expected to be observed in the proton-proton collision data used.
%
%
%
%all the effects observed in 
%
%Typically, most of the discrepancies observed can be accounted for by applying various corrective scale factors.
%Where a particular process is poorly described and/or lacking sufficient statistics in the signal region, data-driven estimates of the background are used to model ...

\section{Data and Simulation Samples}\label{sec:samples}
Out of the 37.8\fbinv of the proton-proton collision data at $\sqrt{13}$ collected by CMS during 2016, 35.8\fbinv was certified by the collaboration as ``good'' to be used for physics analysis.

The difference between the certified value and the total data recorded is the result of various factors such as the unavailability of a detector.
Due to the prescaling of the electron triggers during the start of the most luminous runs, as discussed in Chapter~\ref{sec:triggerStrategy}, the ee channel uses a reduced dataset of 35.6\fbinv were none of the triggers considered were prescaled.
Events in the double lepton and single lepton datasets from across these ``good'' data runs are considered where the double and single lepton triggers respectively have fired, using the strategy described in Chapter~\ref{sec:triggerStrategy}.

The MC samples used to model signal and background processes that were considered are listed in Table~\ref{tab:mcList}, which includes information on the number of events generated, their cross sections and the order in perturbative accuracy in QCD to which the generators calculated the processes.

To determine the impact of a number of theoretical uncertainties for a number of processes, a several dedicated samples, listed in Table~\ref{tab:theorySampleList}, were used.
These systematic uncertainties are discussed further in Chapter~\ref{sec:theorySysts}.

For all the MC samples considered, the hadronisation of all the MC samples considered was undertaken using PYTHIA 8.
The NNPDF3.0 family of PDF sets was used as input for the generators of the MC samples, where the corresponding PDF sets were used depending on whether the sample was produced at LO or NLO and used either the four or five flavour scheme.

\begin{table}[htbp]
\topcaption {
The MC processes and their associated total number of events, cross sections and generators (and order in perturbative QCD accuracy they are calculated to), considered for the search for tZq in the dilepton final state. Both generators considered for the Z+jet background are also listed below.
}
\label{tab:mcList}
  \centering
  \resizebox{\textwidth}{!}{
% This right-aligns numbers in column, but centers them under column title.
 \begin{tabular}{cccc}
   \hline
   \textbf{MC process} & \textbf{Events} & \textbf{Cross section (pb)} & \textbf{Generator (Order)}   \\
   \hline
   tZq  & 14.5M & 0.0758  & aMC@NLO (NLO) \\
   \hline
   tHq  & 3.5M & 0.07462  & Madgraph (LO) \\
   \hline
   tWZ/tWll  & 50K & 0.01104  & Madgraph (LO) \\
   \hline
   t tW-channel & 7M & 35.85 & POWHEG (NLO) \\
   $\overline{\text{t}}$ tW-channel & 6.9M & 35.85 & POWHEG (NLO) \\
   \hline
   t s-channel & 2.9M & 10.32 & aMC@NLO (NLO) \\
   \hline
   t t-channel & 67.2M & 136.02 & POWHEG (NLO) \\
   $\overline{\text{t}}$ t-channel & 38.8M & 80.95 & POWHEG (NLO) \\
   \hline
   \ttbar & 77.1M & 831.76 & POWHEG (NLO) \\
   \hline
   \ttbarZ $\rightarrow$ ll$\nu\nu$ & 13.9M & 0.2529   & aMC@NLO (NLO) \\
   \ttbarZ $\rightarrow$ qq & 749K & 0.5297   & aMC@NLO (NLO) \\
   \hline
   \ttbarW $\rightarrow$ l$\nu$ & 5.3M & 0.2001   & aMC@NLO (NLO) \\
   \ttbarW $\rightarrow$ qq & 833K & 0.405  & aMC@NLO (NLO) \\
   \hline
   \ttbarH $\rightarrow$ bb & 3.8M & 0.2942 & POWHEG (NLO) \\
           $\rightarrow$ non bb & 4.0M & 0.2123 & POWHEG (NLO) \\
   \hline
   W+jets & 24.1M & 61526.7 & aMC@NLO (NLO) \\
   \hline
   Z+jets ($m_{Z} \geq 50\GeVcc $ & 146M & 5765.4 & Madgraph (LO) \\
   Z+jets ($10 \GeVcc \leq m_{Z} < 50\GeVcc$ & 35.3M & 18610.0 & Madgraph (LO) \\
   \hline
   Z+jets ($m_{Z} \geq 50\GeVcc $ & 151M & 5765.4 & aMC@NLO (NLO) \\
   Z+jets ($10 \GeVcc \leq m_{Z} < 50\GeVcc$ & 106M & 18610.0 & aMC@NLO (NLO) \\
   \hline
   WW $\rightarrow$ l$\nu$qq & 9.0M & 49.997  & POWHEG (NLO) \\
      $\rightarrow$ ll$nu\nu$ & 2.0M & 12.178 & POWHEG (NLO) \\
   \hline
   WZ $\rightarrow$ l$\nu$qq & 24.2M & 10.73 & aMC@NLO (NLO) \\
      $\rightarrow$ llqq & 26.5M & 5.606 & aMC@NLO (NLO) \\
      $\rightarrow$ lll$\nu$ 1.9M & 5.26 & aMC@NLO (NLO) \\
   \hline
   ZZ $\rightarrow$ ll$\nu\nu$ & 8.8M & 0.5644 & POWHEG (NLO) \\
      $\rightarrow$ llqq & 15.3M & 3.222 & aMC@NLO (NLO) \\
      $\rightarrow$ llll & 10.7M & 1.204 & aMC@NLO (NLO) \\
   \hline
   WWW & 240K & 0.2086 & aMC@NLO (NLO) \\
   \hline
   WWZ & 250K & 0.1651 & aMC@NLO (NLO) \\
   \hline
   WZZ & 247K & 0.05565 & aMC@NLO (NLO) \\
   \hline
   ZZZ & 249K & 0.01398 & aMC@NLO (NLO) \\
   \hline
   
 \end{tabular}}
\end{table}

\begin{table}[htbp]
\topcaption {
The dedicated MC samples used to determine the impact of theoretical uncertainties, including the associated total number of events, cross sections and generators (and order in perturbative QCD accuracy they are calculated to), considered for the search for tZq in the dilepton final state.
}
\label{tab:theorySampleList}
  \centering
 \resizebox{\textwidth}{!}{
 \begin{tabular}{cccc}
   \hline
   \textbf{MC process} & \textbf{Events} & \textbf{Cross section (pb)} & \textbf{Generator (Order)}   \\
   \hline
   tZq scale up & 6.9M & 0.0758  & aMC@NLO (NLO) \\
   tZq scale down & 7.0M & 0.0758  & aMC@NLO (NLO) \\
   \hline
   t tW-channel scale up & 998K & 35.85 & POWHEG (NLO) \\
   t tW-channel scale down & 994K & 35.85 & POWHEG (NLO) \\
   $\overline{\text{t}}$ tW-channel scale down & 1.0M & 35.85 & POWHEG (NLO) \\
   $\overline{\text{t}}$ tW-channel scale down & 999K & 35.85 & POWHEG (NLO) \\
   \hline
   t t-channel scale up & 5.7M & 136.02 & POWHEG (NLO) \\
   t t-channel scale down & 5.9M & 136.02 & POWHEG (NLO) \\
   t t-channel matching up & 6.0M & 136.02 & POWHEG (NLO) \\
   t t-channel matching down & 6.0M & 136.02 & POWHEG (NLO) \\
   $\overline{\text{t}}$ t-channel scale up & 4.0M & 80.95 & POWHEG (NLO) \\
   $\overline{\text{t}}$ t-channel scale down & 3.9M & 80.95 & POWHEG (NLO) \\
   $\overline{\text{t}}$ t-channel matching up & 4.0M & 80.95 & POWHEG (NLO) \\
   $\overline{\text{t}}$ t-channel matching down & 4.0M & 80.95 & POWHEG (NLO) \\
   \hline
   \ttbar ISR up & 156.5M & 831.76 & POWHEG (NLO) \\
   \ttbar ISR down & 149.8M & 831.76 & POWHEG (NLO) \\
   \ttbar FSR up & 152.6M & 831.76 & POWHEG (NLO) \\
   \ttbar FSR down & 156.0M & 831.76 & POWHEG (NLO) \\
   \ttbar matching up & 58.9M & 831.76 & POWHEG (NLO) \\
   \ttbar matching down & 58.2M & 831.76 & POWHEG (NLO) \\
   \hline   
 \end{tabular}}
\end{table}

\section{Simulation Corrections}\label{sec:simCorrections}
Simulation is unable to fully recreate all the effects observed in data, either because certain parameters are not precisely known or cannot be be calculated.
To account for these discrepancies, corrective scale factors are used to reweight MC on a per event basis.
Such scale factors are usually derived as a function of \pt and $\eta$ so as to account for the variation of the detector response in both.
These corrections are used to correct simulation for lepton identification, isolation and reconstruction efficiencies, b-tagging efficiencies, the poor modelling of pileup in simulation, and the detector resolutions observed in data.

\subsection{Miscalibrated Tracker APV}\label{subsec:hipEffect}
During the first half of data taking in 2016 the silicon strip detector suffered from instantaneous luminosity dependent  hit finding inefficiencies, particularly in high occupancy regions, due to saturation in the pre-amplifier in the front end electronics~\cite{Fiori:2016ebh}.
This issue was resolved by changing the configuration of the electronics.
While the affected part of the dataset has been reprocessed to mitigate the impact on the quality of the data taken, there is still a negative impact on the detector efficiency for objects that rely upon highly efficient tracking data.
This is accounted for by the weighting of events appropriately when the scale factors are produced, either centrally by CMS or those derived for the analysis (\ie the trigger scale factors), so that a single scale factor is applied to a simulated event.

%In most cases, centrally produced scale factors are derived for the whole of the 2016 dataset to account for this, but 
%for muons they were provided for both the affected and unaffected parts of the dataset separately.
%Consequently, the muon scale factors were weighted according to the luminosity they corresponded to before their application to simulation.
%Similarly, the muon trigger scale factors that were derived were also produced 

\subsection{Lepton Efficiency}\label{subsec:leptonRecoSFs}
The identification, isolation and reconstruction efficiencies of leptons are calculated using measurements of $Z \rightarrow l^{+} l ^{-}$ events with the \emph{tag-and-probe} method~\cite{CMS:2008rxa}.
Using events within a dilepton invariant mass window to ensure a high purity, from this large statistics lepton sample, the method ``tags'' and ``probes'' the leptons where one has passed a tight and the other a loose selection criteria.
For source of each efficiency and lepton flavour, the efficiency is given as the fraction of events where the probe leptons passed the relevant selection criteria.
This methodology is used to create corrective scale factors for each component and these are multiplicatively applied to each leptons' event weight as functions of their \pt, $\eta$, and flavour.

The trigger efficiency of electrons and muons is calculated using a method which considers events that pass the lepton selection criteria in the signal region~\ref{sec:signalRegion} and which are selected by triggers which are weakly correlated (also known as cross triggers) with the triggers used in the analysis~\cite{Khachatryan:2016kzg}.
From this collection of events, the number of events that pass and fail the analysis triggers are counted to produce the trigger efficiency:

\begin{equation}
\epsilon_{trigger} = \frac{N_{X triggers + lepton triggers}}{N_{X triggers}} \\
\end{equation}

where $N_{X trigger}$ is the number of events which have passed the lepton selection criteria and the cross triggers, and $N_{X triggers + lepton triggers}$ is $N_{X trigger}$ and the number of events which have also passed the lepton triggers.

As the triggers requirements are applied to both simulated and data events, a scale factor of the ratio of the trigger efficiency in data and in simulation is applied to the event weight in simulation.

%For the scale factors derived for the ee and e$\mu$ channels, a constant scale factor was found to be sufficient to account for the differences between data and siulation.
%In the case of the $\mu\mu$ channel however, the scale factor was produced as a function of both \pt and $\eta$ due to the trigger turn-on curve in data being impacted by the miscalibrated tracker APV (as discussed in Chapter~\ref{subsec:hipEffect}.

\subsection{Lepton Energy Corrections}\label{subsec:leptonEnergyCorrections}
\subsubsection{Electron Regression and Energy Scale and Smearing Corrections}
Two types of energy corrections which have been produced by the CMS EGM POG are applied to electrons and photons, energy regression and energy scale and smearing corrections.
These corrections are applied to both MC simulation and data and are used to improve the electron resolution obtained and to resolve the observed discrepancies between them.

Using simulation for tuning, energy regression obtains the best possible energy resolution by using the detector information to correct the reconstructed object energy.
The disagreement between data and MC is resolved by scaling the data energy to the MC energy scale and smearing the MC so that it has the same energy resolution as data. 

These corrections are pre-applied onto the PF electron collections used.

\subsubsection{Rochester Corrections}
The muon momentum scale and resolution correction methods developed by the University of Rochester~\cite{rochester}, known as \emph{Rochester Corrections}, are used to remove any muon momentum bias from any detector misalignment, reconstruction or uncertainties in the magnetic field for both MC and data.
These corrections are derived with high \pt ($> 20\GeVc$) muons from Z $ \rightarrow \mu\mu$ decays using a two step method, where the muons are binned in charge, $\eta$ and $\phi$.
The first step requires the mean inverse transverse momenta of the muons reconstructed from data and simulation to be the same as the corresponding values from a perfectly aligned detector.
These corrections are tuned in the second step by using the $M_{\mu^{+1}\mu^{-1}}$ peak for a perfectly aligned detector to calibrate the corrections.
This removes any sensitivity to detector efficiencies or physics modelling.

The Rochester Corrections are applied to each muon an event weight that is a function of the muon's charge, \pt, $\eta$ and $phi$.

\subsection{Jet Energy Corrections}\label{subsec:jesjer}
As described in Chapter~\ref{subsubsec:JECs}, the JECs are applied to account for the non-uniform response in \pT and $eta$ of the detector by comparing the differences between the generator level and detector level responses.

In addition to these corrections, as the Jet Energy Resolution (JER) observed in data is approximately 10\% poorer than that in observed simulation, the 4-vectors of simulated jets are smeared as functions of generator level and reconstructed \pt and $\eta$ to account for this~\cite{Khachatryan:2016kdb}.

\subsection{b-tagging Efficiency}\label{subsec:btagEff}
The B-Tag and Vertexing (BTV) Physics Object Group measures the b-tagging efficiency and misidentification rates for b and light flavoured jets in data and MC simulation (multijet and \ttbar) of the algorithms which they support~\cite{Sirunyan:2017ezt}.
From these measurements b-tagging efficiency scale factors are produced and provided for analysts to apply to simulated events to correct differences observed between data and simulation.
These scale factors, as functions of the jet flavour, \pT and $\eta$, to alter the weight of the selected MC events.
This methodology was chosen as it involves only changing the weight of the selected MC events which, unlike other methods, avoids events migrating into different b-tag multiplicity bins and having events with potentially undefined variables such as the top mass.

\subsection{\PU Modelling}\label{subsec:puSF}
It is challenging to model variations in the number of \PU interactions that result from the changing LHC conditions.
Therefore MC events are reweighted as a function of the number of primary vertices so that the PU interactions simulated are resembles what is observed in data.

The \PU SF is determined as a function of the number of primary vertices, $n_{PV}$, present by comparing $n_{PV}$ in minimum bias data over the running period considered to $n_{PV}$ for simulated events.

\subsection{Top quark \pt}
A scale factor is applied to \ttbar MC as a function of the top's and anti-top's generator level transverse momenta to account for the \pt spectra of top quarks in data being significantly softer than that predicted by LO and NLO precision MC simulation~\cite{Khachatryan:2015oqa}.


\section{Signal Region Simulated Backgrounds}\label{sec:simBackgrounds}
The impact of the application of the full event selection and simulation corrections in the signal region on the simulated samples is shown in Table~\ref{tab:signalYields}.

The jet cleaning and tight isolation criteria for leptons 
It is clear that despite the high purity selection criteria used to reject the majority of the Z+jets, it remains the dominant background

The 

\begin{table}[!htbp]
\topcaption{The number of observed events in data and the number of expected events in simulation in the signal region fllowing the full event selection for each of the separate channels and with both channels combined.}\label{tab:signalYields}
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
Channel &  $ee$ & $\mu\mu$ & Combined \\
\hline
Signal (SM tZq) & 30.242 &  54.508 & 84.750     \\
Backgrounds: & & & \\
tWZ\@: & 6.439 & 10.779 & 17.218    \\
tHq: & 0.173 & 0.372 & 0.545    \\
ttW\@: & 7.249 & 10.681 & 17.930    \\
ttZ\@: & 61.882 & 110.471 & 172.353    \\
ttH\@: & 4.916 & 9.554 & 14.470    \\
\ttbar: & 1653.457 & 3219.360 & 482.817    \\
tW\@: & 95.989 & 177.527 & 273.516    \\
s-channel: & 0.000 & 0.000 & 0.000    \\
t-channel: & 0.612 & 0.995 & 1.607    \\
WW\@: & 1.339 & 2.4475 & 3.786    \\
WZ\@: & 73.466 & 126.656 & 200.122    \\
ZZ\@: & 51.827 & 92.980 & 144.807    \\
WWW\@: & 0.114 & 0.305 & 0.419    \\
WWZ\@: & 1.327 & 2.207 & 3.534    \\
WZZ\@: & 1.540 & 2.470 & 4.010    \\
ZZZ\@: & 0.661 & 1.087 & 1.748    \\
W + jets: & 0.000 & 0.000 & 0.000    \\
Z + jets: & 3293.634 & 6245.353 & 9538.987    \\
\hline
NPLs: & 37.787 & 30.889 & 68.676   \\
\hline
Data & 5284 & 9665 & 14949    \\
Total MC & 5284.867 & 10067.752 & 15352.619    \\
Total MC + NPLs & 5322.654 & 10098.641 & 15361.377    \\
\hline
\end{tabular}
\end{table}

\section{Data-driven Background Estimation}\label{sec:dataDrivenBackground}

\subsection{Non-Prompt Leptons}\label{sec:NPLs}
Leptons which are produced from events where at least one jet is incorrectly reconstructed as a lepton (predominately electrons) or a lepton from the decay of heavy quarks (predominately muons) are known as \emph{non-prompt leptons} (NPLs).
Given the difficulty in accurately modelling QCD processes and the very low statistics of such processes passing the lepton selection and isolation criteria, the NPL contribution is estimated with data.

The data-driven background estimation of background NPL background uses the same methodology as top quark pair production~\cite{CMS:2016syx} and same charge SUSY searches~\cite{CMS:2015vqc}.
This approach takes advantage of the fact that the vast majority of the event yields for same charge lepton pairs are result from non-prompt and charge misidentified leptons, with some contribution from prompt leptons.
As these backgrounds are independent of the charge of the lepton pairs, it is expected that the nominal opposite charge event selection would have a similar contribution.

Therefore by inverting the signal region's oppositely charged lepton requirement (\ie the leptons must have the same charge), a same charge control region can be defined which is dominated by NPL events while containing some contributions from prompt lepton events, charge misidentification and real same charge pairs.

Using this control region, a data-driven estimate of the contribution of opposite charge NPLs can be derived using Equation~\ref{eq:NPL}:

\begin{equation}
 N_{data}^{OS non-prompt} = (N_{data}^{SS} - N^{SS}_{real + mis-ID}).\frac{N_{MC}^{OS non-prompt}}{N_{MC}^{SS non-prompt}}
\end{equation}\label{eq:NPL}

where $N_{data}^{SS}$ is the total number of same charge events observed in data and $N^{SS}_{real + mis-ID}$ is the expected number of real same charge events and events with charge misidentification.

The ratio of opposite charge and same charge NPLs in simulation, $N_{MC}^{OS non-prompt}$ and $N_{MC}^{SS non-prompt}$,
is used to appropriately normalise this estimate and uses the generator level information to correctly identify how the leptons were produced.
The W+jets, \ttZ, \ttW, and single top simulated samples which have sufficient statistics in the control region are used to calculate this ratio as these processes are expected to be the predominant source of non-prompt leptons for this analysis.

The event yields of the simulated samples and data following the full event selection in the same lepton charge control region, ratio of same charge to opposite charge event yields and the estimated NPL contribution are given in Table~\ref{tab:fakeLeptonYields}.
It is found that ...

\begin{table}[!htbp]
\topcaption{The same charge event yields, ratio of same to opposite charge lepton events and the estimated non-prompt lepton contribution following all selection cuts.}
\centering
\begin{tabular}{| l |  c |  c |  c |  c |  c |}
\hline
Source &  $ee$ & $\mu\mu$ & Combined \\ 
\hline
\ttbar (SS): & a &  c  & e    \\
Z + jets (SS): & a &  c & e$\pm$r    \\
Single Top (SS): & a & c & e$\pm$r    \\
VV (SS): & a & c & e    \\
ttV (SS): & a &  c & e    \\ 
\hline
Total background (SS): & a & c & e   \\ 
Data: & a & c & e    \\ 
\hline
SS data (bkg): & a & c & e \\
\hline
Non-prompt (SS): & a & c & e \\
Non-prompt (OS): & a & c & e \\
R (OS/SS): & a & c & e \\
\hline
NPL estimation: & a & c & e \\
\hline
\end{tabular}
\label{tab:fakeLeptonYields}
\end{table}

\subsection{Z+jets background}\label{subsec:zPlusJetsEstimation}
Following the application of the full event selection in the signal region, it was observed that while the Z+jets sample produced using Madgraph 
Madgraph - normalises well but poor jet multiplicity
aMC@NLO - bad normalisation, but good higher jet multiplicity description

\begin{table}[!htbp]
\topcaption{The number of observed events in data and the number of expected events in simulation in the signal region fllowing the full event selection for each of the separate channels and with both channels combined.}\label{tab:zPlusControlYields}
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
Channel &  $ee$ & $\mu\mu$ & Combined \\
\hline
tZq & 30.242 &  54.508 & 84.750     \\
tWZ\@: & 6.439 & 10.779 & 17.218    \\
tHq: & 0.173 & 0.372 & 0.545    \\
ttW\@: & 7.249 & 10.681 & 17.930    \\
ttZ\@: & 61.882 & 110.471 & 172.353    \\
ttH\@: & 4.916 & 9.554 & 14.470    \\
\ttbar: & 1653.457 & 3219.360 & 482.817    \\
tW\@: & 95.989 & 177.527 & 273.516    \\
s-channel: & 0.000 & 0.000 & 0.000    \\
t-channel: & 0.612 & 0.995 & 1.607    \\
WW\@: & 1.339 & 2.4475 & 3.786    \\
WZ\@: & 73.466 & 126.656 & 200.122    \\
ZZ\@: & 51.827 & 92.980 & 144.807    \\
WWW\@: & 0.114 & 0.305 & 0.419    \\
WWZ\@: & 1.327 & 2.207 & 3.534    \\
WZZ\@: & 1.540 & 2.470 & 4.010    \\
ZZZ\@: & 0.661 & 1.087 & 1.748    \\
W + jets: & 0.000 & 0.000 & 0.000    \\
Z + jets: & 3293.634 & 6245.353 & 9538.987    \\
\hline
NPLs: & 37.787 & 30.889 & 68.676   \\
\hline
Data & 5284 & 9665 & 14949    \\
Total MC & 5284.867 & 10067.752 & 15352.619    \\
Total MC + NPLs & 5322.654 & 10098.641 & 15361.377    \\
\hline
\end{tabular}
\end{table}

\subsection{\ttbar background}\label{subsec:ttbarEstimation}
The \ttbar enriched control region defined in Chapter~\ref{subsec:ttbarCR} was designed to provide an orthogonal region which was topologically similar to the signal region in order to validate:
\begin{itemize}
\item whether or not the simulated \ttbar sample used accurately modelled the \ttbar process;
\item and if not, to be used to derive a data-driven estimate for \ttbar.
\end{itemize}

\begin{table}[htbp]
\topcaption {
The event yields after the selection criteria have been applied for the \ttbar control region.
}
\label{tab:ttbarCR}
  \centering
% This right-aligns numbers in column, but centers them under column title.
 \begin{tabular}{cc}
   \hline
   \textbf{MC process} & \textbf{$e\mu$}  \\
   \hline
   tZq & 1.709\\
   \ttbar & 11778.461 \\
   Z+jets & 80.9921\\
   tW & 488.632\\
   Other & 166.200\\
   \hline
   Data & 12509.0 \\
   Total MC & 12515.995 \\
   \hline
 \end{tabular}
\end{table}

\section{Multivariate Analysis Techniques}\label{sec:mvas}
Multivariate Analysis (MVA) techniques are commonly used to further enhance the separation between signal and background processes given the difficulty in identifying rare or background dominated processes through the sole use of individual cuts.

Therefore, given the small cross section and topology of the dilepton final state of tZq, a MVA method was used to enhance the separation between the signal and background following the application of the selection cuts described in Chapter~\ref{chapter:tzq-search}.
The \emph{Boosted Decision Tree}~(BDT) MVA technique was used as it a widely used and supported technique which those undertaking this analysis were familiar with.

\subsection{Boosted Decision Trees}\label{subsec:bdt}
A decision tree in its simplest form is a series of sequential binary decisions (nodes) on a single variable at a time in order classify an event as signal or background.

\emph{Boosting} extends the concept of a decision tree from a single tree to a forest of trees with the aim of both stabilising the decision trees' response and enhancing their performance.
This involves training multiple trees in succession on the same training sample which has been reweighted based on the past trees' performance.
At the end of the process all the trees are combined into a single classifier which is given by the weighted average of the trees, thus creating a strong learner out of an ensemble of weak learners.

\emph{Bagging} is a similar concept to boosting, but involves each tree being trained on a random subset of the training sample, where every element has an equal probability of being sampled, rather than the whole training sample.

Following the evaluation of a number of Boosting and Bagging algorithms for decision trees, it was determined that the
\emph{eXtreme Gradient Boosting} (XGBoost) implementation of the Gradiant Boost alogorithm provided the optimal performance for the search presented~\cite{xgboost}.

The \emph{Gradient Boost} algorithm~\cite{Friedman:GradientBoosting} models the shortcomings of the model 


This exponential loss approach however, is its degraded performance in noisier environments as it is not robust in 	

The number of nodes or \emph{depth} of the tree considered
As each node's criteria are dependent on those which have preceded it, the decision tree is capable of separating signal 

\emph{Overtraining}
A training sample, consisting of a subset of the data to be classified, is used as the input 




The methods used for selecting the input variables (features) and model hyperparameters are described in the following subsections.
Both the features and model hyperparameters were chosen separately for ee and mumu channels.

\subsection{BDT Input Features}
From the selected reconstructed physics objects, a large number of input variables or \emph{features} were constructed and considered as potential inputs for the BDT.

In order to determine which of set of features was optimal, recursive feature elimination was used to select those which had the greatest discriminating power between the signal and background process.
This process iteratively removes the least important feature and re-trains the BDT until every feature has been ranked in order of their removal.
Following each removal of a feature, the area under the Receiver Operating Characteristic (ROC) curve is recorded.
The features found above the point at which the area under the ROC curve experiences a significant decline are determined to be an optimal correlated set of features.
 
The features chosen by recursive feature elimination for the $ee$ and $\mu\mu$ channels are given in Table~\ref{tab:selectedBdtVariables}, with the full list of features considered, and their ability to separate between signal and background, being given in full in Table~\ref{tab:fullBdtVariables}

\begin{table}[htbp]
\topcaption {The name and descriptions of the variables chosen by recursive feature elimination to be used as input to the BDT to discriminate between potential tZq signal events and the dominant backgrounds.
}
\label{tab:selectedBdtVariables}
  \centering
% This increases column spacing.
\resizebox{\textwidth}{!}{
% This right-aligns numbers in column, but centers them under column title.
\begin{tabular}{cccc}
   \hline
   \textbf{Variable} & \textbf{Description} & \textbf{$ee$} & \textbf{$\mu\mu$} \\
   \hline
    bTagDisc & b-tag discriminator of the leading b-tagged jet & $\checkmark$ & $\checkmark$ \\
    fourthJetPt & \pt of the fourth jet & $\checkmark$ & $\checkmark$ \\
    jetHt & Total \HT of every jet & $X$ & $\checkmark$ \\
    jetMass & Total mass of every jet & $\checkmark$ & $\checkmark$ \\
    jjDelR & $\Delta R$ between the leading jets & $\checkmark$ & $\checkmark$ \\
    leadJetEta & $\eta$ of the leading jet & $\checkmark$ & $\checkmark$ \\
    leadJetPt & \pt of the leading jet & $\checkmark$ & $\checkmark$ \\
    met & \met & $\checkmark$ & $\checkmark$ \\
    secJetPt & \pt of the second jet & $\checkmark$ & $\checkmark$ \\
    thirdJetPt & \pt of the third jet & $\checkmark$ & $\checkmark$ \\
    topMass & $m_{top}$ & $\checkmark$ & $\checkmark$ \\
    totHtOverPt & Total \HT divided by total \pt & $\checkmark$ & $\checkmark$ \\
    wPairMass & $m_{W}$ & $\checkmark$ & $\checkmark$ \\
    wQuark2Eta & $\eta$ of the second W boson candidate jet & $X$ & $\checkmark$ \\
    wwdelR & $\Delta R$ between the W boson candidate jets & $\checkmark$ & $X$ \\
    zEta & $\eta$ of the Z boson & $X$$ & $\checkmark$ \\
    zHt & \HT of the Z boson & $\checkmark$ & $\checkmark$ \\
    zMass & $m_{Z}$ & $\checkmark$ & $\checkmark$ \\
    zTopDelR & $\Delta R$ between the Z boson and top quark & $X$ & $\checkmark$ \\
    zjminR & Minimum $\Delta R$ between the Z boson and a jet & $\checkmark$ & $\checkmark$ \\
    zlb1DelR & $\Delta R$ between the Z boson and leading b-tagged jet & $\checkmark$ & $X$ \\
   \hline
 \end{tabular}}
\end{table}

\editComment{LOTS of PLOTS of the input variable distributions}

\subsection{BDT Model Hyperparameters}
The model hyperparameters are the set of parameters which are set before the BDT training begins, such the maximum depth trees can be grown to or the number of training iterations to be run. 
Rather than tune the hyperparmeter selection by hand or run a computationally expensive and time consuming grid search of all the possible hyperparameters to optimise the classifier's performance, the optimal hyperparameters were selected using a Gaussian process.


Hyperparameters are selected by using a Gaussian process to optimise the classifier’s performance
hyperparameters = learning rate, n-estimators, max tree depth

    n_jobs: 20 - number of training iterations
    n_estimators: 4818 - 
    subsample: 0.6794502469027806
    learning_rate: 0.004457105002157622
    max_depth: 4
    min_child_weight: 0.016143380898361325 - Minimum sum of instance weight (hessian) needed in a child
    gamma: 7.588559443997618 - minimum loss function used to make a further partition on a leaf node of the tree
    reg_lambda: 0.0006395600995084355
    reg_alpha: 0.00037293584840804463

\subsection{BDT Output}
Following the optimisation of both the BDT features and hyperparameters for both the ee and $\mu\mu$ channels independently, the optimal BDT is trained and used to produce an output distribution of the BDT discriminator for each of the data and background samples considered.
The resultant BDT discriminator distributions are used to perform a measurement of the signal strength and to attempt an extraction of the signal's cross section.